{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d10f4f50-cb3a-4bfb-97e8-b63bedc3f9d3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Databricks notebook: 05_gold/01_build_gold_tables\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 0) Guardrails / quick visibility\n",
    "# -----------------------------------------------------------------------------\n",
    "print(\"Building Gold tables from Silver...\")\n",
    "\n",
    "# Source of truth for Gold facility-month grain\n",
    "silver_canon = \"tp_finance.silver.contract_facility_monthly_canonical\"\n",
    "\n",
    "# Gold targets\n",
    "gold_facility_fact = \"tp_finance.gold.fact_facility_monthly\"\n",
    "gold_contract_summary = \"tp_finance.gold.fact_contract_monthly_summary\"\n",
    "gold_dim_month = \"tp_finance.gold.dim_month\"\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 1) Build/Upsert Gold facility-month fact\n",
    "# -----------------------------------------------------------------------------\n",
    "src_fac = spark.table(silver_canon).select(\n",
    "    \"customer_id\",\"contract_id\",\"facility_id\",\"month\",\"currency\",\n",
    "    F.col(\"drawn_this_month\").cast(\"decimal(18,2)\").alias(\"drawn_this_month\"),\n",
    "    F.col(\"repaid_this_month\").cast(\"decimal(18,2)\").alias(\"repaid_this_month\"),\n",
    "    F.col(\"net_movement\").cast(\"decimal(18,2)\").alias(\"net_movement\"),\n",
    "    F.col(\"opening_balance\").cast(\"decimal(18,2)\").alias(\"opening_balance\"),\n",
    "    F.col(\"closing_balance\").cast(\"decimal(18,2)\").alias(\"closing_balance\"),\n",
    "    \"balance_source\",\n",
    "    F.col(\"balance_diff\").cast(\"decimal(18,2)\").alias(\"balance_diff\"),\n",
    "    \"is_mismatch\",\n",
    "    \"is_backfilled\",\n",
    "    \"load_ts\",\n",
    ")\n",
    "\n",
    "src_fac.createOrReplaceTempView(\"stg_gold_facility_monthly\")\n",
    "\n",
    "spark.sql(f\"\"\"\n",
    "MERGE INTO {gold_facility_fact} t\n",
    "USING stg_gold_facility_monthly s\n",
    "ON  t.customer_id = s.customer_id\n",
    "AND t.contract_id = s.contract_id\n",
    "AND t.facility_id = s.facility_id\n",
    "AND t.month       = s.month\n",
    "WHEN MATCHED THEN UPDATE SET *\n",
    "WHEN NOT MATCHED THEN INSERT *;\n",
    "\"\"\")\n",
    "\n",
    "fac_count = spark.table(gold_facility_fact).count()\n",
    "print(f\"Gold facility-month fact rows: {fac_count}\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 2) Rebuild Gold contract-month summary deterministically\n",
    "#    (TRUNCATE+INSERT avoids merge anomalies; it's standard for small/medium)\n",
    "# -----------------------------------------------------------------------------\n",
    "spark.sql(f\"TRUNCATE TABLE {gold_contract_summary}\")\n",
    "\n",
    "spark.sql(f\"\"\"\n",
    "INSERT INTO {gold_contract_summary}\n",
    "SELECT\n",
    "  customer_id,\n",
    "  contract_id,\n",
    "  month,\n",
    "  MAX(currency) AS currency,\n",
    "\n",
    "  CAST(SUM(drawn_this_month) AS DECIMAL(18,2))  AS total_drawn,\n",
    "  CAST(SUM(repaid_this_month) AS DECIMAL(18,2)) AS total_repaid,\n",
    "  CAST(SUM(net_movement) AS DECIMAL(18,2))      AS net_movement,\n",
    "  CAST(SUM(closing_balance) AS DECIMAL(18,2))   AS closing_balance,\n",
    "\n",
    "  COUNT(DISTINCT facility_id)                   AS facilities,\n",
    "  SUM(CASE WHEN is_mismatch THEN 1 ELSE 0 END)  AS mismatched_rows,\n",
    "\n",
    "  MAX(load_ts)                                  AS load_ts\n",
    "FROM {gold_facility_fact}\n",
    "GROUP BY customer_id, contract_id, month\n",
    "\"\"\")\n",
    "\n",
    "summary_count = spark.table(gold_contract_summary).count()\n",
    "print(f\"Gold contract-month summary rows: {summary_count}\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 3) Rebuild dim_month from gold facility fact bounds (month grain)\n",
    "# -----------------------------------------------------------------------------\n",
    "bounds = spark.table(gold_facility_fact).agg(\n",
    "    F.min(\"month\").alias(\"min_m\"),\n",
    "    F.max(\"month\").alias(\"max_m\")\n",
    ").collect()[0]\n",
    "\n",
    "min_m = bounds[\"min_m\"]\n",
    "max_m = bounds[\"max_m\"]\n",
    "\n",
    "if min_m is None or max_m is None:\n",
    "    print(\"No months found in gold fact. Skipping dim_month rebuild.\")\n",
    "else:\n",
    "    months = (spark.range(1)\n",
    "        .select(F.explode(F.sequence(F.lit(min_m), F.lit(max_m), F.expr(\"interval 1 month\"))).alias(\"month\"))\n",
    "        .select(\n",
    "            F.col(\"month\").cast(\"date\").alias(\"month\"),\n",
    "            F.date_format(F.col(\"month\"), \"yyyyMM\").cast(\"int\").alias(\"month_key\"),\n",
    "            F.year(F.col(\"month\")).alias(\"year\"),\n",
    "            F.month(F.col(\"month\")).alias(\"month_num\"),\n",
    "            F.date_format(F.col(\"month\"), \"MMMM\").alias(\"month_name\"),\n",
    "            F.date_format(F.col(\"month\"), \"yyyy-MM\").alias(\"year_month\"),\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # overwrite dim table each run (standard for dims derived from facts)\n",
    "    (months.write\n",
    "        .mode(\"overwrite\")\n",
    "        .option(\"overwriteSchema\", \"true\")\n",
    "        .saveAsTable(gold_dim_month)\n",
    "    )\n",
    "\n",
    "    dim_count = spark.table(gold_dim_month).count()\n",
    "    print(f\"Gold dim_month rows: {dim_count}\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 4) Optional: quick reconciliation assertion (should be 0 mismatches)\n",
    "# -----------------------------------------------------------------------------\n",
    "recon = spark.sql(f\"\"\"\n",
    "SELECT count(*) AS bad_rows\n",
    "FROM {gold_contract_summary} s\n",
    "JOIN (\n",
    "  SELECT customer_id, contract_id, month,\n",
    "         CAST(SUM(drawn_this_month) AS DECIMAL(18,2))  AS total_drawn_check,\n",
    "         CAST(SUM(repaid_this_month) AS DECIMAL(18,2)) AS total_repaid_check,\n",
    "         CAST(SUM(closing_balance) AS DECIMAL(18,2))   AS closing_balance_check\n",
    "  FROM {gold_facility_fact}\n",
    "  GROUP BY customer_id, contract_id, month\n",
    ") f\n",
    "ON s.customer_id=f.customer_id AND s.contract_id=f.contract_id AND s.month=f.month\n",
    "WHERE s.total_drawn <> f.total_drawn_check\n",
    "   OR s.total_repaid <> f.total_repaid_check\n",
    "   OR s.closing_balance <> f.closing_balance_check\n",
    "\"\"\").collect()[0][\"bad_rows\"]\n",
    "\n",
    "print(\"Reconciliation bad_rows:\", recon)\n",
    "if recon != 0:\n",
    "    raise Exception(f\"Gold reconciliation failed: {recon} mismatched contract-month rows\")\n",
    "\n",
    "print(\"Gold build complete.\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "build_gold_tables",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
